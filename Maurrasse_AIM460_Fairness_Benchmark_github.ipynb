{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16f8b9f",
   "metadata": {
    "id": "c16f8b9f"
   },
   "source": [
    "# **AIM460 Capstone â€” Cross-Domain Algorithmic Fairness Benchmark**\n",
    "**Runtime:** Google Colab (GPU recommended)\n",
    "\n",
    "**Methods:** DSAP (pre), Equalized Odds via Exponentiated Gradient (in), Threshold Optimizer (post), FRAME/SLSD stubs, DeAR (vision).  \n",
    "**Datasets:** ACSIncome, ACSEmployment, COMPAS, CivilComments (manual upload), FairFace (optional demo).\n",
    "**Metrics:** Accuracy, AUC, EO gap (TPR), Eq-Odds gaps (TPR/TNR).\n",
    "**Exports:** figures/CSVs in `/content/exports/` + release + Overleaf pack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VZccmFvih-oN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZccmFvih-oN",
    "outputId": "eeb561bb-cc9d-408a-dbec-2fcc25fd9eb4"
   },
   "outputs": [],
   "source": [
    "# ðŸš« Disable W&B globally (prevents login prompt)\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"DISABLE_WANDB\"] = \"true\"\n",
    "print(\"âœ… Global W&B disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_iQf5_5HpJvH",
   "metadata": {
    "id": "_iQf5_5HpJvH"
   },
   "outputs": [],
   "source": [
    "# ðŸ§¹ Remove wandb completely so nothing can call it\n",
    "!pip -q uninstall -y wandb pathtools setproctitle docker-pycreds GitPython sentry-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e9585",
   "metadata": {
    "id": "c41e9585"
   },
   "source": [
    "## 2) Colab Setup (Install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633aa102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "633aa102",
    "outputId": "74911d12-ac13-4753-a48e-a85dc0031fc2"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Install Runtime Dependencies (CUDA 12.1 stack)\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install \"pandas==2.2.2\" \"scikit-learn>=1.4,<1.6\" \"matplotlib>=3.8,<3.10\" \"shap>=0.45,<0.47\"\n",
    "!pip -q install \"fairlearn>=0.12,<0.14\" \"folktables>=0.0.12\" \"datasets>=2.20,<2.22\" \"evaluate>=0.4,<0.5\" \"transformers>=4.44,<4.47\"\n",
    "!pip -q install --index-url https://download.pytorch.org/whl/cu121 \"torch==2.4.0\" \"torchaudio==2.4.0\" \"torchvision==0.19.0\"\n",
    "!pip -q install \"nbformat>=5.10,<6\" \"python-pptx>=0.6.21,<0.7\" \"tabulate>=0.9,<0.10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c3de0",
   "metadata": {
    "id": "af8c3de0"
   },
   "outputs": [],
   "source": [
    "#@title Conflict Clean-up (safe to run once after installing dependencies)\n",
    "# Removes unused packages that force incompatible pins in Colab.\n",
    "# Run this *after* the Install cell finishes, then go to: Runtime â†’ Restart runtime.\n",
    "!pip -q uninstall -y umap-learn gcsfs\n",
    "!pip -q install \"scikit-learn==1.5.2\" \"fsspec==2024.6.1\" --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13917dc6",
   "metadata": {
    "id": "13917dc6"
   },
   "source": [
    "After installs: **Runtime â†’ Restart runtime**, then run **Environment Check**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7403d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed7403d7",
    "outputId": "78d82d7a-45fc-4937-99e5-3017edfcda3f"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Environment Check\n",
    "import importlib, torch\n",
    "\n",
    "def ok(v): return f\"âœ… {v}\"\n",
    "def warn(v): return f\"âš ï¸ {v}\"\n",
    "\n",
    "def check_version(pkg, pref=None):\n",
    "    try:\n",
    "        m = importlib.import_module(pkg); v = getattr(m, \"__version__\", \"unknown\")\n",
    "        return ok(f\"{pkg}=={v}\") if (pref is None or v.startswith(pref)) else warn(f\"{pkg}=={v} (expect {pref})\")\n",
    "    except Exception as e:\n",
    "        return warn(f\"{pkg} import failed: {e}\")\n",
    "\n",
    "print(check_version(\"torch\",\"2.4\"))\n",
    "print(ok(f\"CUDA available: {torch.cuda.is_available()}\"))\n",
    "if torch.cuda.is_available():\n",
    "    print(ok(f\"Device: {torch.cuda.get_device_name(0)}\")); print(ok(f\"CUDA: {torch.version.cuda}\"))\n",
    "for p, pref in [(\"sklearn\",None),(\"pandas\",\"2.2\"),(\"matplotlib\",None),(\"fairlearn\",None),(\"folktables\",None),(\"datasets\",None),(\"evaluate\",None),(\"transformers\",None),(\"shap\",None)]:\n",
    "    print(check_version(p,pref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89dbd9f",
   "metadata": {
    "id": "c89dbd9f"
   },
   "source": [
    "### âœ… What to run next (after Environment Check)\n",
    "1. Run **Utility Functions (metrics, plotting, exports)**  \n",
    "2. **Folktables** â†’ run **ACSIncome** then **ACSEmployment** (baseline â†’ DSAP â†’ Eq-Odds â†’ Threshold Optimizer â†’ plot)  \n",
    "3. **COMPAS** â†’ download/preprocess â†’ methods â†’ plot  \n",
    "4. **CivilComments (Text)** â†’ upload `train.csv` â†’ move & verify â†’ run baseline + plot  \n",
    "5. **FairFace (Optional)** â†’ run toy DeAR demo + plot  \n",
    "6. **Aggregated Results** â†’ write/preview `results_summary_all.csv`  \n",
    "7. **Sanitize & Export** â†’ creates cleaned notebook, release ZIP, and Overleaf pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef483c34",
   "metadata": {
    "id": "ef483c34"
   },
   "source": [
    "## 3) Utility Functions (metrics, plotting, exports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75e1e6",
   "metadata": {
    "id": "aa75e1e6"
   },
   "outputs": [],
   "source": [
    "#@title Helper: Exponentiated Gradient Probability Extraction\n",
    "import numpy as np\n",
    "\n",
    "def eg_probabilities(eg, X):\n",
    "    \"\"\"Return class-1 probabilities for ExponentiatedGradient across fairlearn versions.\"\"\"\n",
    "    if hasattr(eg, \"_pmf_predict\"):\n",
    "        try:\n",
    "            pmf = eg._pmf_predict(X)\n",
    "            return pmf[:, 1]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(eg, \"predictors_\"):\n",
    "        probs = []\n",
    "        for est in eg.predictors_:\n",
    "            if hasattr(est, \"predict_proba\"):\n",
    "                probs.append(est.predict_proba(X)[:, 1])\n",
    "            elif hasattr(est, \"decision_function\"):\n",
    "                s = est.decision_function(X)\n",
    "                probs.append(1 / (1 + np.exp(-s)))\n",
    "            else:\n",
    "                probs.append(est.predict(X).astype(float))\n",
    "        P = np.vstack(probs)\n",
    "        if hasattr(eg, \"weights_\") and eg.weights_ is not None:\n",
    "            w = np.asarray(eg.weights_, dtype=float)\n",
    "            w = w / w.sum()\n",
    "            return (w @ P).ravel()\n",
    "        else:\n",
    "            return P.mean(axis=0)\n",
    "    return eg.predict(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb60699",
   "metadata": {
    "id": "beb60699"
   },
   "outputs": [],
   "source": [
    "#@title Helper: Threshold Optimizer Evaluation\n",
    "def evaluate_threshold_optimizer(cal, to, X_test, y_test, g_test, dataset_name):\n",
    "    \"\"\"Evaluate calibrated probabilities + post-processed labels, then log summary.\"\"\"\n",
    "    y_score = cal.predict_proba(X_test)[:, 1]\n",
    "    y_pred  = to.predict(X_test, sensitive_features=g_test)\n",
    "    m_to = evaluate_binary(y_test, y_score, y_pred, g_test)\n",
    "    add_summary_row(dataset_name, \"threshold_optimizer\", m_to)\n",
    "    return m_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755e612",
   "metadata": {
    "id": "3755e612"
   },
   "outputs": [],
   "source": [
    "#@title Helper: Trade-off Plot + CSV Export (utility â†‘ vs EO gap â†“)\n",
    "import pandas as pd\n",
    "def export_tradeoff_points(points, dataset_key, title):\n",
    "    df = pd.DataFrame(points, columns=[\"label\",\"accuracy\",\"eo_tpr_gap\"]).dropna()\n",
    "    csv_path = f\"/content/exports/{dataset_key}_points.csv\"\n",
    "    png_path = f\"/content/exports/{dataset_key}_tradeoff.png\"\n",
    "    save_results_csv(df, csv_path)\n",
    "    tradeoff_plot(df, \"accuracy\", \"eo_tpr_gap\", title, png_path)\n",
    "    flush_summary_csv(\"/content/exports/results_summary_all.csv\")\n",
    "    return csv_path, png_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154146ea",
   "metadata": {
    "id": "154146ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Utilities\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "EXPORT_DIR=\"/content/exports\"; os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "def tpr_fpr(y_true, y_pred, pos=1):\n",
    "    y_true=np.asarray(y_true); y_pred=np.asarray(y_pred)\n",
    "    tp=np.sum((y_true==pos)&(y_pred==pos)); fn=np.sum((y_true==pos)&(y_pred!=pos))\n",
    "    tn=np.sum((y_true!=pos)&(y_pred!=pos)); fp=np.sum((y_true!=pos)&(y_pred==pos))\n",
    "    tpr=tp/(tp+fn+1e-12); fpr=fp/(fp+tn+1e-12); tnr=1-fpr; return tpr,fpr,tnr\n",
    "\n",
    "def group_gaps(y_true, y_pred, g):\n",
    "    import pandas as pd, numpy as np\n",
    "    df=pd.DataFrame({\"y\":y_true,\"yp\":y_pred,\"g\":g})\n",
    "    tprs, tnrs = [], []\n",
    "    for _,sub in df.groupby(\"g\"):\n",
    "        tpr, fpr, tnr = tpr_fpr(sub.y, sub.yp); tprs.append(tpr); tnrs.append(tnr)\n",
    "    eo = float(np.max(tprs)-np.min(tprs)) if tprs else np.nan\n",
    "    tnr_gap = float(np.max(tnrs)-np.min(tnrs)) if tnrs else np.nan\n",
    "    return {\"eo_tpr_gap\":eo, \"eqodds_tpr_gap\":eo, \"eqodds_tnr_gap\":tnr_gap}\n",
    "\n",
    "def evaluate_binary(y_true, y_score, y_pred, g):\n",
    "    out={\"accuracy\": float(accuracy_score(y_true, y_pred))}\n",
    "    try: out[\"auc\"]=float(roc_auc_score(y_true, y_score))\n",
    "    except: out[\"auc\"]=float(\"nan\")\n",
    "    out.update(group_gaps(y_true, y_pred, g)); return out\n",
    "\n",
    "def tradeoff_plot(df, x, y, title, out_png):\n",
    "    plt.figure(); plt.scatter(df[x], df[y])\n",
    "    for _,r in df.iterrows():\n",
    "        if isinstance(r.get(\"label\"), str): plt.annotate(r[\"label\"], (r[x], r[y]))\n",
    "    plt.xlabel(f\"{x} (â†‘)\"); plt.ylabel(f\"{y} (â†“)\"); plt.title(title); plt.grid(True)\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "def save_results_csv(df, path): df.to_csv(path, index=False)\n",
    "\n",
    "RESULTS_SUMMARY=[]\n",
    "def add_summary_row(dataset, method, metrics):\n",
    "    row={\"dataset\":dataset,\"method\":method}; row.update(metrics); RESULTS_SUMMARY.append(row)\n",
    "def flush_summary_csv(path=\"/content/exports/results_summary_all.csv\"):\n",
    "    pd.DataFrame(RESULTS_SUMMARY).to_csv(path, index=False) if RESULTS_SUMMARY else pd.DataFrame([],columns=[\"dataset\",\"method\",\"accuracy\",\"auc\",\"eo_tpr_gap\",\"eqodds_tpr_gap\",\"eqodds_tnr_gap\"]).to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526de73a",
   "metadata": {
    "id": "526de73a"
   },
   "source": [
    "## 4) Folktables â€” ACSIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2f69b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaf2f69b",
    "outputId": "879e1e5e-f8e1-45c1-cd2f-648da4b69a10"
   },
   "outputs": [],
   "source": [
    "#@title Aligned loaders for Folktables (use task-returned group)\n",
    "from folktables import ACSDataSource, ACSIncome, ACSEmployment\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def _binarize_group(g_task: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert Folktables' returned group vector to {0,1}.\n",
    "    Commonly '1' corresponds to White in RAC1P; we map (==1) -> 1 else 0.\n",
    "    If it's already 0/1, we return as-is.\n",
    "    \"\"\"\n",
    "    g = np.asarray(g_task)\n",
    "    if set(np.unique(g)).issubset({0, 1}):\n",
    "        return g.astype(int)\n",
    "    try:\n",
    "        return (g.astype(int) == 1).astype(int)\n",
    "    except Exception:\n",
    "        return (g > np.median(g)).astype(int)\n",
    "\n",
    "def load_acs_income(state=\"CA\", year=2018, horizon=\"1-Year\"):\n",
    "    ds = ACSDataSource(survey_year=year, horizon=horizon, survey=\"person\")\n",
    "    acs = ds.get_data(download=True, states=[state])\n",
    "    X, y, g_task = ACSIncome.df_to_numpy(acs)  # aligned group from task\n",
    "    g = _binarize_group(g_task)\n",
    "    return X, y, g\n",
    "\n",
    "def load_acs_employment(state=\"CA\", year=2018, horizon=\"1-Year\"):\n",
    "    ds = ACSDataSource(survey_year=year, horizon=horizon, survey=\"person\")\n",
    "    acs = ds.get_data(download=True, states=[state])\n",
    "    X, y, g_task = ACSEmployment.df_to_numpy(acs)\n",
    "    g = _binarize_group(g_task)\n",
    "    return X, y, g\n",
    "\n",
    "def split_scale(X, y, g, test_size=0.25, seed=42):\n",
    "    Xtr, Xte, ytr, yte, gtr, gte = train_test_split(X, y, g, test_size=test_size, random_state=seed, stratify=y)\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    Xtr = sc.fit_transform(Xtr)\n",
    "    Xte = sc.transform(Xte)\n",
    "    return Xtr, Xte, ytr, yte, gtr, gte, sc\n",
    "\n",
    "# --- Run income loader and baseline ---\n",
    "X, y, g = load_acs_income()\n",
    "Xtr, Xte, ytr, yte, gtr, gte, _ = split_scale(X, y, g)\n",
    "\n",
    "base = LogisticRegression(max_iter=200, n_jobs=-1).fit(Xtr, ytr)\n",
    "ys = base.predict_proba(Xte)[:, 1]\n",
    "yp = (ys >= 0.5).astype(int)\n",
    "\n",
    "m_base = evaluate_binary(yte, ys, yp, gte)\n",
    "add_summary_row(\"acs_income\", \"baseline\", m_base)\n",
    "m_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87504db9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87504db9",
    "outputId": "6d3b5df2-cc7d-44cf-ed65-2c8e8c9102e3"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title DSAP-style reweighting\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "def dsap_reweight(y,g):\n",
    "    pairs=list(zip(y,g)); c=Counter(pairs)\n",
    "    w=np.array([1.0/c[(yy,gg)] for yy,gg in pairs],dtype=float); return w*(len(w)/w.sum())\n",
    "w=dsap_reweight(ytr,gtr)\n",
    "dsap=LogisticRegression(max_iter=200,n_jobs=-1).fit(Xtr,ytr,sample_weight=w)\n",
    "ys2=dsap.predict_proba(Xte)[:,1]; yp2=(ys2>=0.5).astype(int)\n",
    "m_dsap=evaluate_binary(yte, ys2, yp2, gte); add_summary_row(\"acs_income\",\"dsap_reweight\",m_dsap); m_dsap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdef500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cdef500",
    "outputId": "60817558-725a-4ee4-f1f5-4b6db69a9aff"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Equalized Odds via ExponentiatedGradient\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "eg=ExponentiatedGradient(DecisionTreeClassifier(max_depth=4,random_state=0), EqualizedOdds(), eps=0.02, max_iter=50)\n",
    "eg.fit(Xtr,ytr,sensitive_features=gtr)\n",
    "ys3 = eg_probabilities(eg, Xte)\n",
    "yp3=(ys3>=0.5).astype(int)\n",
    "m_eg=evaluate_binary(yte, ys3, yp3, gte); add_summary_row(\"acs_income\",\"eq_odds_eg\",m_eg); m_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56682d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a56682d7",
    "outputId": "06fc7a03-4ea9-445f-abd2-4713802ac511"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Threshold Optimizer (Post-Processing on Calibrated Scores)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split for calibration and validation\n",
    "Xc_tr, Xc_val, yc_tr, yc_val, gc_tr, gc_val = train_test_split(\n",
    "    Xtr, ytr, gtr, test_size=0.2, random_state=3, stratify=ytr\n",
    ")\n",
    "\n",
    "# 1ï¸âƒ£ Fit the base logistic regression first\n",
    "base_lr = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "base_lr.fit(Xc_tr, yc_tr)\n",
    "\n",
    "# 2ï¸âƒ£ Calibrate probabilities (no prefit flag â†’ CalibratedClassifierCV will refit internally)\n",
    "cal = CalibratedClassifierCV(base_lr, cv=3, method=\"isotonic\")\n",
    "cal.fit(Xc_tr, yc_tr)\n",
    "\n",
    "# 3ï¸âƒ£ Fit Fairlearn ThresholdOptimizer for Equalized Odds\n",
    "to = ThresholdOptimizer(\n",
    "    estimator=cal,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "to.fit(Xc_val, yc_val, sensitive_features=gc_val)\n",
    "\n",
    "# 4ï¸âƒ£ Evaluate calibrated + post-processed results\n",
    "m_to = evaluate_threshold_optimizer(cal, to, Xte, yte, gte, \"acs_income\")\n",
    "m_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58cdce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ae58cdce",
    "outputId": "504f01f9-6705-4314-d289-8517b3433bf5"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Plot & export (income)\n",
    "import pandas as pd\n",
    "df=pd.DataFrame([\n",
    "    {\"label\":\"baseline\",\"accuracy\":m_base[\"accuracy\"],\"eo_tpr_gap\":m_base[\"eo_tpr_gap\"]},\n",
    "    {\"label\":\"dsap\",\"accuracy\":m_dsap[\"accuracy\"],\"eo_tpr_gap\":m_dsap[\"eo_tpr_gap\"]},\n",
    "    {\"label\":\"eq_odds\",\"accuracy\":m_eg[\"accuracy\"],\"eo_tpr_gap\":m_eg[\"eo_tpr_gap\"]},\n",
    "    {\"label\":\"thresh_opt\",\"accuracy\":m_to[\"accuracy\"],\"eo_tpr_gap\":m_to[\"eo_tpr_gap\"]},\n",
    "])\n",
    "png=\"/content/exports/income_tradeoff.png\"\n",
    "tradeoff_plot(df,\"accuracy\",\"eo_tpr_gap\",\"ACSIncome: Utility vs Fairness (EO gap)\",png)\n",
    "save_results_csv(df,\"/content/exports/acs_income_points.csv\"); flush_summary_csv(); png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88830714",
   "metadata": {
    "id": "88830714"
   },
   "source": [
    "## 5) Folktables â€” ACSEmployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3ab70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "f0b3ab70",
    "outputId": "4e89f1ae-3d07-4631-c91f-422069b803ec"
   },
   "outputs": [],
   "source": [
    "#@title Folktables: ACSEmployment (Tabular Fairness Benchmark)\n",
    "from folktables import ACSEmployment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 1ï¸âƒ£ Load and split\n",
    "Xe, ye, ge = load_acs_employment()\n",
    "XtrE, XteE, ytrE, yteE, gtrE, gteE, scE = split_scale(Xe, ye, ge)\n",
    "\n",
    "# 2ï¸âƒ£ Baseline Logistic Regression\n",
    "baseE = LogisticRegression(max_iter=200, n_jobs=-1).fit(XtrE, ytrE)\n",
    "ysEb = baseE.predict_proba(XteE)[:, 1]\n",
    "ypEb = (ysEb >= 0.5).astype(int)\n",
    "mEb = evaluate_binary(yteE, ysEb, ypEb, gteE)\n",
    "add_summary_row(\"acs_employment\", \"baseline\", mEb)\n",
    "print(\"âœ… Baseline metrics:\")\n",
    "display(mEb)\n",
    "\n",
    "# 3ï¸âƒ£ DSAP-style reweighting (pre-processing fairness)\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "wE = compute_sample_weight(\"balanced\", ytrE)\n",
    "lr_dsapE = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "lr_dsapE.fit(XtrE, ytrE, sample_weight=wE)\n",
    "ysEd = lr_dsapE.predict_proba(XteE)[:, 1]\n",
    "ypEd = (ysEd >= 0.5).astype(int)\n",
    "mEd = evaluate_binary(yteE, ysEd, ypEd, gteE)\n",
    "add_summary_row(\"acs_employment\", \"dsap\", mEd)\n",
    "print(\"âœ… DSAP metrics:\")\n",
    "display(mEd)\n",
    "\n",
    "# 4ï¸âƒ£ Equalized Odds (ExponentiatedGradient)\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "egE = ExponentiatedGradient(\n",
    "    DecisionTreeClassifier(max_depth=4, random_state=0),\n",
    "    EqualizedOdds(),\n",
    "    eps=0.02\n",
    ")\n",
    "egE.fit(XtrE, ytrE, sensitive_features=gtrE)\n",
    "\n",
    "ysEe = eg_probabilities(egE, XteE)\n",
    "ypEe = (ysEe >= 0.5).astype(int)\n",
    "mEe = evaluate_binary(yteE, ysEe, ypEe, gteE)\n",
    "add_summary_row(\"acs_employment\", \"eq_odds_eg\", mEe)\n",
    "print(\"âœ… Equalized Odds (EG) metrics:\")\n",
    "display(mEe)\n",
    "\n",
    "# 5ï¸âƒ£ Threshold Optimizer (Post-Processing on Calibrated Scores)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "# Split training data into calibration (train) and validation subsets\n",
    "Xc_trE, Xc_valE, yc_trE, yc_valE, gc_trE, gc_valE = train_test_split(\n",
    "    XtrE, ytrE, gtrE, test_size=0.2, random_state=3, stratify=ytrE\n",
    ")\n",
    "\n",
    "# Base classifier\n",
    "base_lrE = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "base_lrE.fit(Xc_trE, yc_trE)\n",
    "\n",
    "# Calibrate probabilities (cv=3 avoids prefit issues)\n",
    "calE = CalibratedClassifierCV(base_lrE, cv=3, method=\"isotonic\")\n",
    "calE.fit(Xc_trE, yc_trE)\n",
    "\n",
    "# Threshold Optimizer for Equalized Odds\n",
    "toE = ThresholdOptimizer(\n",
    "    estimator=calE,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "toE.fit(Xc_valE, yc_valE, sensitive_features=gc_valE)\n",
    "\n",
    "# Evaluate calibrated + post-processed results\n",
    "mE_to = evaluate_threshold_optimizer(calE, toE, XteE, yteE, gteE, \"acs_employment\")\n",
    "print(\"âœ… Threshold Optimizer metrics:\")\n",
    "display(mE_to)\n",
    "\n",
    "# 6ï¸âƒ£ Trade-off plot + CSV export\n",
    "_ = export_tradeoff_points(\n",
    "    [\n",
    "        {\"label\":\"baseline\",   \"accuracy\": mEb[\"accuracy\"], \"eo_tpr_gap\": mEb[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"dsap\",       \"accuracy\": mEd[\"accuracy\"], \"eo_tpr_gap\": mEd[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"eq_odds\",    \"accuracy\": mEe[\"accuracy\"], \"eo_tpr_gap\": mEe[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"thresh_opt\", \"accuracy\": mE_to[\"accuracy\"], \"eo_tpr_gap\": mE_to[\"eo_tpr_gap\"]},\n",
    "    ],\n",
    "    dataset_key=\"employment\",\n",
    "    title=\"ACSEmployment: Utility vs Fairness (EO gap)\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Exported trade-off plot and CSV for ACSEmployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d509c73",
   "metadata": {
    "id": "5d509c73"
   },
   "source": [
    "## 6) COMPAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pT9YQ1kxKAAF",
   "metadata": {
    "id": "pT9YQ1kxKAAF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c3948",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "a04c3948",
    "outputId": "a7cbc4b4-72d6-4fee-e75b-5128c2990b78"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title COMPAS: Auto-download, preprocess, fairness experiments, plot + export\n",
    "import os, pandas as pd, numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ---------- 1) Download & Load ----------\n",
    "compas_dir = \"/content/data/compas\"\n",
    "os.makedirs(compas_dir, exist_ok=True)\n",
    "compas_csv = os.path.join(compas_dir, \"compas-scores-two-years.csv\")\n",
    "\n",
    "if not os.path.exists(compas_csv):\n",
    "    print(\"Downloading COMPAS from ProPublica GitHub...\")\n",
    "    url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "    urlretrieve(url, compas_csv)\n",
    "\n",
    "df = pd.read_csv(compas_csv)\n",
    "\n",
    "# ---------- 2) Minimal, reproducible preprocessing ----------\n",
    "# Keep common fields used in many public baselines\n",
    "cols_keep = [\n",
    "    \"age\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\",\n",
    "    \"priors_count\", \"c_charge_degree\", \"race\", \"sex\", \"two_year_recid\"\n",
    "]\n",
    "df = df[cols_keep].dropna()\n",
    "\n",
    "# Label: two_year_recid (1=reoffended within two years)\n",
    "yC = df[\"two_year_recid\"].astype(int).values\n",
    "\n",
    "# Sensitive attribute: race (African-American=1, others=0)\n",
    "gC = (df[\"race\"].astype(str).str.strip() == \"African-American\").astype(int).values\n",
    "\n",
    "# Features: numeric + one-hot for c_charge_degree and sex\n",
    "X_num = df[[\"age\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\"]].astype(float)\n",
    "X_cat = pd.get_dummies(df[[\"c_charge_degree\", \"sex\"]].astype(str), drop_first=True)\n",
    "XC = pd.concat([X_num, X_cat], axis=1).values\n",
    "\n",
    "# ---------- 3) Train/test split + scaling (uses your split_scale helper) ----------\n",
    "XtrC, XteC, ytrC, yteC, gtrC, gteC, scC = split_scale(XC, yC, gC)\n",
    "\n",
    "# ---------- 4) Baseline ----------\n",
    "baseC = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "baseC.fit(XtrC, ytrC)\n",
    "ysCb = baseC.predict_proba(XteC)[:, 1]\n",
    "ypCb = (ysCb >= 0.5).astype(int)\n",
    "mCb = evaluate_binary(yteC, ysCb, ypCb, gteC)\n",
    "add_summary_row(\"compas\", \"baseline\", mCb)\n",
    "print(\"âœ… COMPAS Baseline\"); display(mCb)\n",
    "\n",
    "# ---------- 5) DSAP-style reweighting (pre) ----------\n",
    "wC = compute_sample_weight(\"balanced\", ytrC)\n",
    "lr_dsapC = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "lr_dsapC.fit(XtrC, ytrC, sample_weight=wC)\n",
    "ysCd = lr_dsapC.predict_proba(XteC)[:, 1]\n",
    "ypCd = (ysCd >= 0.5).astype(int)\n",
    "mCd = evaluate_binary(yteC, ysCd, ypCd, gteC)\n",
    "add_summary_row(\"compas\", \"dsap\", mCd)\n",
    "print(\"âœ… COMPAS DSAP\"); display(mCd)\n",
    "\n",
    "# ---------- 6) Equalized Odds via ExponentiatedGradient (in) ----------\n",
    "egC = ExponentiatedGradient(\n",
    "    DecisionTreeClassifier(max_depth=4, random_state=0),\n",
    "    EqualizedOdds(),\n",
    "    eps=0.02\n",
    ")\n",
    "egC.fit(XtrC, ytrC, sensitive_features=gtrC)\n",
    "ysCe = eg_probabilities(egC, XteC)          # uses your helper\n",
    "ypCe = (ysCe >= 0.5).astype(int)\n",
    "mCe = evaluate_binary(yteC, ysCe, ypCe, gteC)\n",
    "add_summary_row(\"compas\", \"eq_odds_eg\", mCe)\n",
    "print(\"âœ… COMPAS Equalized Odds (EG)\"); display(mCe)\n",
    "\n",
    "# ---------- 7) Threshold Optimizer on Calibrated Scores (post) ----------\n",
    "# Split a small calibration/validation fold from the training split\n",
    "Xc_trC, Xc_valC, yc_trC, yc_valC, gc_trC, gc_valC = train_test_split(\n",
    "    XtrC, ytrC, gtrC, test_size=0.2, random_state=3, stratify=ytrC\n",
    ")\n",
    "\n",
    "# Base classifier for calibration\n",
    "base_lrC = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "base_lrC.fit(Xc_trC, yc_trC)\n",
    "\n",
    "# Calibrator (cv=3 -> no prefit headaches)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calC = CalibratedClassifierCV(base_lrC, cv=3, method=\"isotonic\")\n",
    "calC.fit(Xc_trC, yc_trC)\n",
    "\n",
    "# Threshold Optimizer for Equalized Odds\n",
    "toC = ThresholdOptimizer(\n",
    "    estimator=calC,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "toC.fit(Xc_valC, yc_valC, sensitive_features=gc_valC)\n",
    "\n",
    "# Evaluate using your helper (calibrated probs + post-processed labels)\n",
    "mC_to = evaluate_threshold_optimizer(calC, toC, XteC, yteC, gteC, \"compas\")\n",
    "print(\"âœ… COMPAS Threshold Optimizer\"); display(mC_to)\n",
    "\n",
    "# ---------- 8) Trade-off plot + CSV export ----------\n",
    "_ = export_tradeoff_points(\n",
    "    [\n",
    "        {\"label\":\"baseline\",   \"accuracy\": mCb[\"accuracy\"],  \"eo_tpr_gap\": mCb[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"dsap\",       \"accuracy\": mCd[\"accuracy\"],  \"eo_tpr_gap\": mCd[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"eq_odds\",    \"accuracy\": mCe[\"accuracy\"],  \"eo_tpr_gap\": mCe[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"thresh_opt\", \"accuracy\": mC_to[\"accuracy\"],\"eo_tpr_gap\": mC_to[\"eo_tpr_gap\"]},\n",
    "    ],\n",
    "    dataset_key=\"compas\",\n",
    "    title=\"COMPAS: Utility vs Fairness (EO gap)\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Exported: /content/exports/compas_points.csv and /content/exports/compas_tradeoff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd70871",
   "metadata": {
    "id": "5bd70871"
   },
   "outputs": [],
   "source": [
    "#@title Methods + plot (COMPAS) â€” fixed & consistent\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Baseline ----------\n",
    "bC = LogisticRegression(max_iter=400, n_jobs=-1).fit(XtrC, ytrC)\n",
    "ysC = bC.predict_proba(XteC)[:, 1]\n",
    "ypC = (ysC >= 0.5).astype(int)\n",
    "mCb = evaluate_binary(yteC, ysC, ypC, gteC)\n",
    "add_summary_row(\"compas\", \"baseline\", mCb)\n",
    "\n",
    "# ---------- DSAP-style reweighting (pre) ----------\n",
    "wC = compute_sample_weight(\"balanced\", ytrC)  # simple DSAP-style weight\n",
    "dC = LogisticRegression(max_iter=400, n_jobs=-1).fit(XtrC, ytrC, sample_weight=wC)\n",
    "ysCd = dC.predict_proba(XteC)[:, 1]\n",
    "ypCd = (ysCd >= 0.5).astype(int)\n",
    "mCd = evaluate_binary(yteC, ysCd, ypCd, gteC)\n",
    "add_summary_row(\"compas\", \"dsap\", mCd)\n",
    "\n",
    "# ---------- Equalized Odds (ExponentiatedGradient) ----------\n",
    "egC = ExponentiatedGradient(\n",
    "    DecisionTreeClassifier(max_depth=4, random_state=0),\n",
    "    EqualizedOdds(),\n",
    "    eps=0.02\n",
    ")\n",
    "egC.fit(XtrC, ytrC, sensitive_features=gtrC)\n",
    "ysCe = eg_probabilities(egC, XteC)      # helper you added\n",
    "ypCe = (ysCe >= 0.5).astype(int)\n",
    "mCe = evaluate_binary(yteC, ysCe, ypCe, gteC)\n",
    "add_summary_row(\"compas\", \"eq_odds_eg\", mCe)\n",
    "\n",
    "# ---------- Threshold Optimizer on calibrated scores (post) ----------\n",
    "# Split off validation from train for threshold optimization\n",
    "Xc_trC, Xc_valC, yc_trC, yc_valC, gc_trC, gc_valC = train_test_split(\n",
    "    XtrC, ytrC, gtrC, test_size=0.2, random_state=3, stratify=ytrC\n",
    ")\n",
    "\n",
    "# Fit base model for calibration\n",
    "base_lrC = LogisticRegression(max_iter=400, n_jobs=-1)\n",
    "base_lrC.fit(Xc_trC, yc_trC)\n",
    "\n",
    "# Calibrate probabilities (cv=3 avoids prefit errors)\n",
    "calC = CalibratedClassifierCV(base_lrC, cv=3, method=\"isotonic\")\n",
    "calC.fit(Xc_trC, yc_trC)\n",
    "\n",
    "# Fairlearn Threshold Optimizer (Equalized Odds)\n",
    "toC = ThresholdOptimizer(\n",
    "    estimator=calC,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "toC.fit(Xc_valC, yc_valC, sensitive_features=gc_valC)\n",
    "\n",
    "# Evaluate via helper: calibrated probs + EO labels\n",
    "mCt = evaluate_threshold_optimizer(calC, toC, XteC, yteC, gteC, \"compas\")\n",
    "\n",
    "# ---------- Trade-off plot + CSV export (standardized filenames) ----------\n",
    "_ = export_tradeoff_points(\n",
    "    [\n",
    "        {\"label\":\"baseline\",   \"accuracy\": mCb[\"accuracy\"], \"eo_tpr_gap\": mCb[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"dsap\",       \"accuracy\": mCd[\"accuracy\"], \"eo_tpr_gap\": mCd[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"eq_odds\",    \"accuracy\": mCe[\"accuracy\"], \"eo_tpr_gap\": mCe[\"eo_tpr_gap\"]},\n",
    "        {\"label\":\"thresh_opt\", \"accuracy\": mCt[\"accuracy\"], \"eo_tpr_gap\": mCt[\"eo_tpr_gap\"]},\n",
    "    ],\n",
    "    dataset_key=\"compas\",\n",
    "    title=\"COMPAS: Utility vs Fairness (EO gap)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a165dfc",
   "metadata": {
    "id": "6a165dfc"
   },
   "source": [
    "## 7) CivilComments â€” manual upload + baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c05248",
   "metadata": {
    "id": "70c05248"
   },
   "source": [
    "Steps: Upload `train.csv` â†’ move to `/content/data/civilcomments/train.csv` â†’ verify â†’ run model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf9a10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86bf9a10",
    "outputId": "660ec8f7-3bd4-4d7f-fe0f-5c0e923d0986"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Move uploaded train.csv\n",
    "import os, shutil\n",
    "src=\"/content/train.csv\"; dst_dir=\"/content/data/civilcomments\"; dst=f\"{dst_dir}/train.csv\"\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "if os.path.exists(src): shutil.move(src, dst)\n",
    "print(\"Exists:\", os.path.exists(dst), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0c854",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ea0c854",
    "outputId": "eb6f3513-1758-4b63-bbaa-a3f47dc1512c"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Verify\n",
    "!ls -l /content/data/civilcomments || echo \"Missing directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ceb24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "be583b7989884ec4a0b86d34c12bfaa7",
      "2703c4e933c445ac9f2ef1ca1443f11a",
      "77607148019c46d7b74b3db4b5fdfcd9",
      "c492e45cb3da436fa1be37a819db2eb8",
      "93d61e24dad744fa971da85b46af168d",
      "28d56ce8addd430491ce765b2f5d3264",
      "ccb2b32640bd44378b349e9aa18abcb7",
      "349bb8e63e5e4e6c84b2da1657288f8e",
      "740620dd2f8541f2853cbca2c7472fef",
      "1af387bc1c6f4167b4eb779e8af7109e",
      "ed5c14b9efeb416eb9d96214ccab47f9",
      "81c7155278014387b49cae9df26be1b5",
      "b1c2e842369f4d48b0cecc7c8258eebb",
      "dfd4e0fa62a14f87880f46535ddc94d9",
      "912440c968594b33ab4eb0ab263feafa",
      "5d39653f6d39477ca76396aff5267d66",
      "4df435530028419b91e3aee0fcdb39b1",
      "fa37a9d58f2243a5bd71d41b69373300",
      "a0bd61a2ec5c4447b58b43fe5ff0ce23",
      "2db416a3596c48d9bb0be6d26c21eb47",
      "4e19202caef44789b0f768fa42e5964f",
      "ab3ec5fcc6bf4bd0965d763d7c070710",
      "93f70bd425e2430889d388ce540a6bc4",
      "bc1a82afd95c48b7a9f8ec845528bb08",
      "4d901cd552b544edb2b7cec5c665dc68",
      "d40e37b23e184450aa8a925574b079ed",
      "914b8b3ca1c9471abae0e9927465c65b",
      "3d809feea731412a93f8e708fb4b2146",
      "966585be9c944c1c8842354dd5d6dfc1",
      "c268c76c7eb84922b87e8009d9564498",
      "6714a85130ca4c9792a073052666bf7d",
      "49274c6d018641d78f17c8226d8835ef",
      "266ca187b55541d3853b454a68c1ac7b",
      "fac126c72e844ceb8451dab609c9decb",
      "18a8aa829a4e46499349a90a381c81a9",
      "dc6dae2fdf7e4ba99d08e3e4ef7a6032",
      "2687d0bd5b0b40ba9b0ba8d34e825d13",
      "826a4585ab024f6d8d312c5cd90e677c",
      "d83ef6ae789642bd85ffdabe16701c5e",
      "14bb94890821466c9427c114f556d906",
      "f3282ae5a6d544199cf8a90a5b65cd0c",
      "a247d97c10ab42ab8862cfab04a1a788",
      "165560acfab44e45a7e018f7e5c3a642",
      "3e44cf21b86f48fd9c04d41e11e5981b",
      "ee7e6b00707544e3855640fb65e25a00",
      "34455704c1774e378427d99a56eab761",
      "388b145d2401462194c9e535dc8e28e6",
      "382de084974d48438eeaed59aebfbdf4",
      "c42bf17bfd1547f79203c6bad97f46ee",
      "7a87d098d05b4426a57cb0d3e76f7b30",
      "bc1f57a3baaa463cb23acdc1a36e4647",
      "f574df3f1b124d19b3642ac326032645",
      "13bfb936aadf4c2397d518eacb1f782c",
      "4a92eabb318c42a8b842dfac17a80338",
      "e3e6dc90c2344b82bdd3dd19e73d4881",
      "c89f4cca9eeb4c68b3f96ba9d7dd74a2",
      "ea7b19cfae594a3084a9e94bc7eb451a",
      "1522723167104dcda2789699b3fe68de",
      "9460841c004b4e2e8f381f36b7875cdb",
      "c3dd33d44e424889afc0f36acd47d009",
      "884d3e848bc241028d2aee5869fa0666",
      "6470c06e564f419ea2412a40a7cf9d7b",
      "54f77471a4044a8c88abc1472fc24c0c",
      "ee191c60a98b4a3491bf5c8e2cdc093e",
      "b1b14c51570747d4ae262519289bd699",
      "34a8e61c0e9f46e994abe26404e367ba",
      "0c548d7e225d4b3db4bb09b588b90b92",
      "15c18e4349c54a9981028e5a8a14c13a",
      "ed3e99e67e0745c48639c021854e22ee",
      "f034b1c5b7964d5496775b70c5bb559f",
      "7567cfe3938f4bddae59ec74adcb749d",
      "7071a1d1e93f4cf8a82561b457a147db",
      "462b1fca895a46d789de2a1731edf31f",
      "1c498467326b43d8bbac7f25e6e0099a",
      "6a61ae2f01164f1fbb416baec59c2b58",
      "1f5bd8cc869745f8bab0ac272838e889",
      "5515d633ca6a4a8cbbf4dad935b7dd1f"
     ]
    },
    "id": "9f2ceb24",
    "outputId": "2eafa1d0-0049-46f3-9ba4-1896b4118a83"
   },
   "outputs": [],
   "source": [
    "#@title Baseline DistilBERT + trade-off plot\n",
    "# ðŸš« Disable Weights & Biases before importing transformers\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"DISABLE_WANDB\"] = \"true\"\n",
    "\n",
    "# --- imports ---\n",
    "import pandas as pd, numpy as np, torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#@title Baseline DistilBERT + trade-off plot\n",
    "import os, pandas as pd, numpy as np, torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "p=\"/content/data/civilcomments/train.csv\"\n",
    "if not os.path.exists(p): raise FileNotFoundError(\"Upload train.csv first.\")\n",
    "df=pd.read_csv(p)\n",
    "text_col=\"comment_text\" if \"comment_text\" in df.columns else \"text\"\n",
    "label_col=\"target\" if \"target\" in df.columns else (\"toxicity\" if \"toxicity\" in df.columns else None)\n",
    "assert text_col in df.columns and label_col in df.columns, \"Need text/comment_text and target/toxicity columns.\"\n",
    "df=df[[text_col,label_col]].rename(columns={text_col:\"text\",label_col:\"label\"}).dropna(); df[\"label\"]=(df[\"label\"]>=0.5).astype(int)\n",
    "df=df.sample(n=min(12000,len(df)),random_state=42)\n",
    "tr,te=train_test_split(df,test_size=0.2,random_state=42,stratify=df[\"label\"])\n",
    "tok=AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokf(b): return tok(b[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "ds_tr=Dataset.from_pandas(tr).map(tokf, batched=True).rename_column(\"label\",\"labels\")\n",
    "ds_te=Dataset.from_pandas(te).map(tokf, batched=True).rename_column(\"label\",\"labels\")\n",
    "ds_tr.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "ds_te.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "from sklearn.metrics import accuracy_score\n",
    "def cm(ep): logits,labels=ep; preds=(logits[:,1]>=0.5).astype(int); return {\"accuracy\":accuracy_score(labels,preds)}\n",
    "args=TrainingArguments(output_dir=\"/content/cc_out\",evaluation_strategy=\"epoch\",logging_strategy=\"epoch\",\n",
    "                       per_device_train_batch_size=16,per_device_eval_batch_size=32,num_train_epochs=1,learning_rate=3e-5,save_strategy=\"no\")\n",
    "trainer=Trainer(model=model,args=args,train_dataset=ds_tr,eval_dataset=ds_te,tokenizer=tok,compute_metrics=cm); trainer.train()\n",
    "model.eval(); probs=[]; labs=[]\n",
    "with torch.no_grad():\n",
    "    for i in range(len(ds_te)):\n",
    "        item={k: ds_te[i][k].unsqueeze(0) for k in [\"input_ids\",\"attention_mask\"]}\n",
    "        out=model(**item); probs.append(torch.softmax(out.logits,dim=-1)[0,1].item()); labs.append(ds_te[i][\"labels\"].item())\n",
    "import numpy as np, pandas as pd\n",
    "y_score=np.array(probs); y_pred=(y_score>=0.5).astype(int); g_test=np.zeros(len(y_pred),dtype=int)\n",
    "m_cc=evaluate_binary(labs, y_score, y_pred, g_test); add_summary_row(\"civilcomments\",\"baseline_distilbert\",m_cc)\n",
    "dfp=pd.DataFrame([{\"label\":\"baseline\",\"accuracy\":m_cc[\"accuracy\"],\"eo_tpr_gap\":m_cc[\"eo_tpr_gap\"]}])\n",
    "png=\"/content/exports/civilcomments_tradeoff.png\"; tradeoff_plot(dfp,\"accuracy\",\"eo_tpr_gap\",\"CivilComments: Utility vs Fairness (EO gap)\",png)\n",
    "save_results_csv(dfp,\"/content/exports/civilcomments_points.csv\"); flush_summary_csv(); png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e7f88",
   "metadata": {
    "id": "5d1e7f88"
   },
   "source": [
    "## 8) Vision (optional) â€” DeAR (toy) + FRAME/SLSD stubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cbb14",
   "metadata": {
    "id": "156cbb14"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title FairFace-like tiny subset (placeholders)\n",
    "import os, pandas as pd, numpy as np\n",
    "from PIL import Image\n",
    "FAIR_DIR=\"/content/data/fairface\"; os.makedirs(FAIR_DIR, exist_ok=True)\n",
    "meta=f\"{FAIR_DIR}/subset.csv\"\n",
    "if not os.path.exists(meta):\n",
    "    rows=[]\n",
    "    for i in range(60):\n",
    "        img=Image.new(\"RGB\",(64,64),(50+3*i%255,100+5*i%255,150+7*i%255))\n",
    "        p=f\"{FAIR_DIR}/img_{i}.png\"; img.save(p); rows.append({\"img_path\":p})\n",
    "    pd.DataFrame(rows).to_csv(meta, index=False)\n",
    "print(\"Subset ready:\", os.path.exists(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40adf4",
   "metadata": {
    "id": "0d40adf4"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title DeAR residualization on embeddings (toy)\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta=\"/content/data/fairface/subset.csv\"\n",
    "if not os.path.exists(meta):\n",
    "    print(\"Skipping DeAR demo.\")\n",
    "else:\n",
    "    df=pd.read_csv(meta)\n",
    "    Z=[]\n",
    "    for p in df[\"img_path\"]:\n",
    "        arr=np.array(Image.open(p)).astype(np.float32)/255.0\n",
    "        Z.append([arr.mean(), arr.std(), arr[...,0].mean(), arr[...,1].mean(), arr[...,2].mean()])\n",
    "    Z=np.asarray(Z); y=(Z[:,0]>np.median(Z[:,0])).astype(int); g=(Z[:,3]>np.median(Z[:,3])).astype(int)\n",
    "    Xtr,Xte,ytr,yte,gtr,gte=train_test_split(Z,y,g,test_size=0.3,random_state=1,stratify=y)\n",
    "    sc=StandardScaler(); Xtr=sc.fit_transform(Xtr); Xte=sc.transform(Xte)\n",
    "    base=LogisticRegression().fit(Xtr,ytr); ys=base.predict_proba(Xte)[:,1]; yp=(ys>=0.5).astype(int)\n",
    "    m_b=evaluate_binary(yte, ys, yp, gte); add_summary_row(\"fairface\",\"baseline_toy\",m_b)\n",
    "    def residualize(Z,g):\n",
    "        Zr=Z.copy().astype(float); A=g.reshape(-1,1); ATA=np.linalg.pinv(A.T@A + 1e-6)\n",
    "        for j in range(Z.shape[1]):\n",
    "            z=Z[:,j:j+1]; beta=ATA @ (A.T@z); Zr[:,j]=(z - A@beta).ravel()\n",
    "        return Zr\n",
    "    Zr=residualize(Z,g); Xtr2,Xte2,ytr2,yte2,gtr2,gte2=train_test_split(Zr,y,g,test_size=0.3,random_state=1,stratify=y)\n",
    "    Xtr2=sc.fit_transform(Xtr2); Xte2=sc.transform(Xte2)\n",
    "    dear=LogisticRegression().fit(Xtr2,ytr2); ys2=dear.predict_proba(Xte2)[:,1]; yp2=(ys2>=0.5).astype(int)\n",
    "    m_d=evaluate_binary(yte2, ys2, yp2, gte2); add_summary_row(\"fairface\",\"dear_residual\",m_d)\n",
    "    import pandas as pd\n",
    "    dfv=pd.DataFrame([{\"label\":\"baseline\",\"accuracy\":m_b[\"accuracy\"],\"eo_tpr_gap\":m_b[\"eo_tpr_gap\"]},\n",
    "                      {\"label\":\"dear\",\"accuracy\":m_d[\"accuracy\"],\"eo_tpr_gap\":m_d[\"eo_tpr_gap\"]}])\n",
    "    png=\"/content/exports/fairface_dear_tradeoff.png\"; tradeoff_plot(dfv,\"accuracy\",\"eo_tpr_gap\",\"FairFace (toy): Utility vs Fairness\",png)\n",
    "    save_results_csv(dfv,\"/content/exports/fairface_points.csv\"); flush_summary_csv(); png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f62f0e",
   "metadata": {
    "id": "74f62f0e"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title FRAME & SLSD stubs\n",
    "FRAME_DESCRIPTION=\"FRAME: augmentation/ensemble-aware reweighting placeholder.\"\n",
    "SLSD_DESCRIPTION=\"SLSD: latent transform neutralizing single sensitive direction (placeholder).\"\n",
    "def FRAME_stub_sample_weights(X,y,g,policy=\"uniform\"):\n",
    "    import numpy as np; return np.ones(len(y),dtype=float)\n",
    "def SLSD_stub_transform(Z,g): return Z\n",
    "print(\"FRAME/SLSD stubs loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f28bd",
   "metadata": {
    "id": "787f28bd"
   },
   "source": [
    "## 9) Aggregated Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead56e2",
   "metadata": {
    "id": "aead56e2"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Write CSV & preview\n",
    "flush_summary_csv(\"/content/exports/results_summary_all.csv\")\n",
    "import pandas as pd; pd.read_csv(\"/content/exports/results_summary_all.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792676c",
   "metadata": {
    "id": "9792676c"
   },
   "source": [
    "## 10) Export & Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede1d9c",
   "metadata": {
    "id": "3ede1d9c"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Sanitize, release bundle, Overleaf pack\n",
    "import os, glob, shutil, zipfile, nbformat, pandas as pd\n",
    "\n",
    "SANITIZED=\"/content/AIM460_Fairness_Benchmark_Final_clean.ipynb\"\n",
    "RELEASE=\"/content/release_bundle\"; OVERLEAF=\"/content/overleaf_pack\"; EXPORTS=\"/content/exports\"\n",
    "os.makedirs(RELEASE, exist_ok=True); os.makedirs(OVERLEAF, exist_ok=True); os.makedirs(EXPORTS, exist_ok=True)\n",
    "\n",
    "# Sanitize: remove widgets metadata from the most recent .ipynb in CWD\n",
    "cands=sorted(glob.glob(\"*.ipynb\"), key=os.path.getmtime, reverse=True)\n",
    "if cands:\n",
    "    nb=nbformat.read(cands[0], as_version=4); nb.metadata.pop(\"widgets\", None)\n",
    "    with open(SANITIZED,\"w\") as f: nbformat.write(nb,f); print(\"Sanitized:\", SANITIZED)\n",
    "else:\n",
    "    print(\"Save notebook first so it appears in CWD.\")\n",
    "\n",
    "# Copy exports + sanitized into release\n",
    "if os.path.exists(SANITIZED): shutil.copy(SANITIZED, RELEASE)\n",
    "for p in glob.glob(f\"{EXPORTS}/*\"): shutil.copy(p, RELEASE)\n",
    "\n",
    "# Slides (pptx) placeholders\n",
    "from pptx import Presentation\n",
    "prs=Presentation()\n",
    "s=prs.slides.add_slide(prs.slide_layouts[0]); s.shapes.title.text=\"Cross-Domain Algorithmic Fairness Benchmark\"; s.placeholders[1].text=\"AIM460 Capstone\"\n",
    "def slide(title, bullets, notes=None):\n",
    "    sl=prs.slides.add_slide(prs.slide_layouts[1]); sl.shapes.title.text=title; tf=sl.placeholders[1].text_frame; tf.clear()\n",
    "    for i,b in enumerate(bullets):\n",
    "        p=tf.add_paragraph() if i else tf.paragraphs[0]; p.text=b\n",
    "    if notes: sl.notes_slide.notes_text_frame.text=notes\n",
    "slide(\"Methods\", [\"DSAP (pre)\", \"Eq-Odds (EG)\", \"Threshold Optimizer\", \"FRAME/SLSD stubs\"], \"Axes: Accuracy â†‘; EO gap â†“\")\n",
    "slide(\"Datasets\", [\"ACSIncome\", \"ACSEmployment\", \"COMPAS\", \"CivilComments\", \"FairFace (opt)\"])\n",
    "slide(\"Tabular Results\", [\"income_tradeoff.png\", \"employment_tradeoff.png\"])\n",
    "slide(\"COMPAS\", [\"compas_tradeoff.png\"])\n",
    "slide(\"Text & Vision\", [\"civilcomments_tradeoff.png\", \"fairface_dear_tradeoff.png\"])\n",
    "slide(\"Key Takeaways\", [\"No single method dominates\", \"Context matters\", \"Calibration helps post-processing\"])\n",
    "slides_path=os.path.join(RELEASE,\"AIM460_slides.pptx\"); prs.save(slides_path)\n",
    "\n",
    "# Overleaf: write files without raw string issues\n",
    "main_lines=[\n",
    "    \"\\documentclass[conference]{IEEEtran}\",\n",
    "    \"\\usepackage{graphicx}\",\n",
    "    \"\\usepackage{booktabs}\",\n",
    "    \"\\usepackage{hyperref}\",\n",
    "    \"\\begin{document}\",\n",
    "    \"\\title{Cross-Domain Algorithmic Fairness Benchmark}\",\n",
    "    \"\\author{AIM460 Capstone}\",\n",
    "    \"\\maketitle\",\n",
    "    \"\\begin{abstract}\",\n",
    "    \"We present a cross-domain benchmark evaluating pre-, in-, and post-processing fairness methods across multiple modalities.\",\n",
    "    \"\\end{abstract}\",\n",
    "    \"\\section{Introduction}\",\n",
    "    \"% \\cite{intro}\",\n",
    "    \"\\section{Related Work}\",\n",
    "    \"% \\cite{fairlearn,frame,dsap,slsd,dear}\",\n",
    "    \"\\section{Methods}\",\n",
    "    \"Pre: DSAP. In: Equalized Odds (Exponentiated Gradient). Post: Threshold Optimizer (calibrated). FRAME/SLSD described and stubbed.\",\n",
    "    \"\\section{Datasets}\",\n",
    "    \"ACSIncome, ACSEmployment, COMPAS, CivilComments, FairFace (toy).\",\n",
    "    \"\\section{Experimental Setup}\",\n",
    "    \"Splits, calibration, sensitive groups.\",\n",
    "    \"\\section{Results}\",\n",
    "    \"See Figs.~\\ref{fig:inc}, \\ref{fig:emp}, \\ref{fig:compas}, \\ref{fig:civil}, \\ref{fig:fairface}.\",\n",
    "    \"\\begin{figure}[t]\\centering\\includegraphics[width=0.9\\linewidth]{income_tradeoff.png}\\caption{ACSIncome: Accuracy (\\uparrow) vs EO gap (\\downarrow).}\\label{fig:inc}\\end{figure}\",\n",
    "    \"\\begin{figure}[t]\\centering\\includegraphics[width=0.9\\linewidth]{employment_tradeoff.png}\\caption{ACSEmployment: Accuracy (\\uparrow) vs EO gap (\\downarrow).}\\label{fig:emp}\\end{figure}\",\n",
    "    \"\\begin{figure}[t]\\centering\\includegraphics[width=0.9\\linewidth]{compas_tradeoff.png}\\caption{COMPAS: Accuracy (\\uparrow) vs EO gap (\\downarrow).}\\label{fig:compas}\\end{figure}\",\n",
    "    \"\\begin{figure}[t]\\centering\\includegraphics[width=0.9\\linewidth]{civilcomments_tradeoff.png}\\caption{CivilComments: Accuracy (\\uparrow) vs EO gap (\\downarrow).}\\label{fig:civil}\\end{figure}\",\n",
    "    \"\\begin{figure}[t]\\centering\\includegraphics[width=0.9\\linewidth]{fairface_dear_tradeoff.png}\\caption{FairFace: Accuracy (\\uparrow) vs EO gap (\\downarrow).}\\label{fig:fairface}\\end{figure}\",\n",
    "    \"\\input{results_summary_all.tex}\",\n",
    "    \"\\section{Discussion}\",\n",
    "    \"Utility/fairness trade-offs across domains.\",\n",
    "    \"\\section{Limitations}\",\n",
    "    \"Proxies for sensitive groups; small subsamples for speed.\",\n",
    "    \"\\section{Conclusion}\",\n",
    "    \"Summary and future work.\",\n",
    "    \"\\bibliographystyle{IEEEtran}\",\n",
    "    \"\\bibliography{references}\",\n",
    "    \"\\end{document}\",\n",
    "]\n",
    "os.makedirs(OVERLEAF, exist_ok=True)\n",
    "with open(os.path.join(OVERLEAF,\"main.tex\"),\"w\") as f: f.write(\"\\n\".join(main_lines))\n",
    "\n",
    "csv=\"/content/exports/results_summary_all.csv\"\n",
    "with open(os.path.join(OVERLEAF,\"results_summary_all.tex\"),\"w\") as f:\n",
    "    if os.path.exists(csv):\n",
    "        import pandas as pd; df=pd.read_csv(csv); f.write(df.to_latex(index=False, float_format=\"%.3f\"))\n",
    "    else:\n",
    "        f.write(\"% Generate results CSV first.\\n\")\n",
    "\n",
    "with open(os.path.join(OVERLEAF,\"references.bib\"),\"w\") as f: f.write(\"% Add your BibTeX entries here.\\n\")\n",
    "\n",
    "# Copy exports into Overleaf\n",
    "for p in glob.glob(f\"{EXPORTS}/*\"): shutil.copy(p, OVERLEAF)\n",
    "\n",
    "# ZIPs\n",
    "def make_zip(root, out):\n",
    "    with zipfile.ZipFile(out, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "        for folder,_,files in os.walk(root):\n",
    "            for fn in files:\n",
    "                fp=os.path.join(folder, fn); z.write(fp, os.path.relpath(fp, root))\n",
    "\n",
    "release_zip=\"/content/AIM460_release_bundle.zip\"; overleaf_zip=\"/content/overleaf_pack.zip\"\n",
    "make_zip(RELEASE, release_zip); make_zip(OVERLEAF, overleaf_zip)\n",
    "print(\"Created:\", release_zip); print(\"Created:\", overleaf_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779fb07",
   "metadata": {
    "id": "2779fb07"
   },
   "source": [
    "### âœ… Final Export Paths\n",
    "- `/content/exports/income_tradeoff.png`\n",
    "- `/content/exports/employment_tradeoff.png`\n",
    "- `/content/exports/compas_tradeoff.png` (if run)\n",
    "- `/content/exports/civilcomments_tradeoff.png` (if run)\n",
    "- `/content/exports/fairface_dear_tradeoff.png` (if run)\n",
    "- `/content/exports/results_summary_all.csv`\n",
    "- Sanitized: `/content/AIM460_Fairness_Benchmark_Final_clean.ipynb`\n",
    "- Release ZIP: `/content/AIM460_release_bundle.zip`\n",
    "- Overleaf ZIP: `/content/overleaf_pack.zip`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "88830714"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
